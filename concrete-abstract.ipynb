{
 "cells": [
  {
   "cell_type": "raw",
   "id": "252fa8cc",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "To create a set of abstrct word embeddings from a set of concrete word embeddings.\n",
    "\n",
    "Strategy:\n",
    "We have three datasets we'll be using:\n",
    "[wac2vec]\n",
    "[WordNet]\n",
    "[Concretness Ratings]\n",
    "\n",
    "\n",
    "Let's create a class to store these and hold functions for manipulating them:\n",
    "[ConcreteAbstract]\n",
    " - isa: class\n",
    " - anchor\n",
    "\n",
    "[AbstractionTree]\n",
    " - anchor\n",
    " - a \"tree\"\n",
    "  - each leaf has a concrete word, embedding, abstraction level\n",
    "  - every parent is an abstract word one (or more?) abstraction level(s) above its children\n",
    "   - contains a classifier that can classify its children\n",
    " - pandas dataframe\n",
    "  - I think pandas will have some useful functions\n",
    "   \n",
    "\n",
    "What are some possible functions we may need?\n",
    "init_abstraction_tree()\n",
    " - takes the three datasets and starts a new tree with the root\n",
    "\n",
    "build_abstraction_tree()\n",
    " - takes the three datasets and builds the [AbstractionTree]\n",
    "  - starts with the leaves and builds towards the root(s)\n",
    " - we can try different kinds of trees using variations of this function\n",
    "\n",
    "\n",
    "build_classifiers()\n",
    " - takes an [AbstractionTree] and builds classifieres for the abstract words\n",
    "\n",
    "\n",
    "\n",
    "Wrapper classes for data?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86653052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/crow/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#import sklearn\n",
    "#from sklearn import metrics\n",
    "#from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "#from wac import WAC\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "#from sklearn import neural_network\n",
    "#import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet as wn\n",
    "from collections import defaultdict as dd\n",
    "import nltk \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3369d5",
   "metadata": {},
   "source": [
    "## Initiate Datasets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbb416b7",
   "metadata": {},
   "source": [
    "f = open('ddata/clip.bertvocab.embeddings.513.txt').readlines()\n",
    "f = [line.split() for line in f]\n",
    "wac2vec = {line[0]:np.array(line[1:], dtype=np.float32) for line in f}\n",
    "pickle.dump(wac2vec, open( \"ddata/clip.bertvocab.embeddings.513.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58f457d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wac2vec = pickle.load(open('ddata/clip.bertvocab.embeddings.513.pkl', 'rb'))\n",
    "len(wac2vec)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0a1ef48",
   "metadata": {},
   "source": [
    "concr_scores = pd.read_csv('ddata/AC_ratings_google3m_koeper_SiW.csv', delimiter='\\t')\n",
    "concr_scores = concr_scores.dropna()\n",
    "concr_scores.WORD = concr_scores.WORD.apply(lambda x: x.replace(\"_\", \" \"))\n",
    "concr_scores.index = concr_scores.WORD\n",
    "pickle.dump(concr_scores, open( \"ddata/AC_ratings_google3m_koeper_SiW.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cb10ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2168990"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concr_scores = pickle.load(open('ddata/AC_ratings_google3m_koeper_SiW.pkl', 'rb'))\n",
    "len(concr_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc199c",
   "metadata": {},
   "source": [
    "## ConcreteAbstract Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac17b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcreteAbstract:\n",
    "    def __init__(self, word_vectors, concr_scores, word_net):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81683a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e13c006a",
   "metadata": {},
   "source": [
    "### Build Abstraction Tree"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b4a74fb",
   "metadata": {},
   "source": [
    "Strategy:\n",
    "Start with a set of concrete words that have embeddings and are in WordNet.\n",
    " - We'll call these Leaves.  All other embeddings are derived from these.\n",
    "\n",
    "[List of Leaf Words]\n",
    "\n",
    "<Attach embedings to these words for later use>\n",
    " - We can put these directly into our abstraction tree\n",
    "\n",
    "[Abstraction Tree]\n",
    "\n",
    "<Find a proper Synset for each leaf\n",
    "\n",
    "[List of Leaf Synsets]\n",
    "\n",
    "<Trim leaves that are ancestors of other leaves>\n",
    "\n",
    "[List of True Leaf Synsets]\n",
    "\n",
    "<Make sure only the True Leaf Synsets are in our [Abstraction Tree]>\n",
    "\n",
    "<Create a list of unprocessed Synsets>\n",
    "\n",
    "[Unprocessed Synsets]\n",
    "\n",
    "<Start \"processing\" each of these [Unprocessed Synsets]>\n",
    " <Find a hypernym>\n",
    " <Add hypernym to [Unprocessed Synsets]>\n",
    "  <Track some information>\n",
    "   - list of direct children?\n",
    "   - list of children and their depths?\n",
    "   - number of leaves\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e089c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def init_abstraction_tree(min_rating=8):\n",
    "\n",
    "    wac_words = list(wac2vec.keys())\n",
    "    wn_words = set(i for i in wn.words())\n",
    "    wn_wac_words = wn_words & set(wac_words)\n",
    "    \n",
    "    concr_scores_subset = concr_scores[concr_scores.RATING >= min_rating]\n",
    "    leaf_words = [w for w in tqdm(wn_wac_words) if w in concr_scores_subset.index]\n",
    "\n",
    "    # Get Leaf Synsets...\n",
    "    leaf_synsets = [wn.synsets(w)[0] for w in leaf_words]\n",
    "\n",
    "    # Initiate Abstraction Tree\n",
    "    embeddings = [wac2vec[w] for w in leaf_words]\n",
    "    data = {\n",
    "        \"SYNSET\" : leaf_synsets,\n",
    "        \"WORD\" : leaf_words,\n",
    "        \"DIST2LEAF\": [0]*len(leaf_synsets),\n",
    "        \"NUM_LEAVES\": [1]*len(leaf_synsets),\n",
    "        \"HYPERNYM\": [[]]*len(leaf_synsets),\n",
    "        \"HYPONYMS\": [[]]*len(leaf_synsets),\n",
    "        \"EMBEDDING\" : embeddings\n",
    "        \n",
    "    }\n",
    "    abstraction_tree = pd.DataFrame(data)\n",
    "    abstraction_tree.index = abstraction_tree.SYNSET\n",
    "\n",
    "    # Get True Leaf Synsets\n",
    "    ancestors = set()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for s in leaf_synsets:\n",
    "            #print(set(s.closure(lambda s: s.hypernyms())))\n",
    "            ancestors = ancestors.union(set(s.closure(lambda s: s.hypernyms())))\n",
    "\n",
    "    # Remove leaves that are ansestors of other leaves\n",
    "    true_leaf_synsets = set(leaf_synsets) - ancestors\n",
    "    ansestor_leaves = set(leaf_synsets) - true_leaf_synsets\n",
    "    abstraction_tree.drop(ansestor_leaves, inplace=True)\n",
    "    \n",
    "    # Remove leaves that have the same Synset\n",
    "    abstraction_tree.drop_duplicates(subset='SYNSET', inplace=True)\n",
    "    \n",
    "    return abstraction_tree"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81d9451d",
   "metadata": {},
   "source": [
    "#abstraction_tree = init_abstraction_tree(3.418)\n",
    "#abstraction_tree = init_abstraction_tree(3.418)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303c7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grow abstraction tree\n",
    "\n",
    "def update_dist2leaf(synset, dist):\n",
    "    h_dist = abstraction_tree.loc[synset, 'DIST2LEAF']\n",
    "    if h_dist > dist:\n",
    "        return\n",
    "    \n",
    "    abstraction_tree.at[synset, 'DIST2LEAF'] = dist\n",
    "    \n",
    "    # go up the hypernym chain and set the distances\n",
    "    h = abstraction_tree.loc[synset, 'HYPERNYM']\n",
    "    if len(h) != 0:\n",
    "        update_dist2leaf(h[0], dist+1)\n",
    "        \n",
    "\n",
    "def update_num_leaves(synset, num_leaves):\n",
    "    orig_num_leaves = abstraction_tree.loc[synset, 'NUM_LEAVES']\n",
    "    abstraction_tree.at[synset, 'NUM_LEAVES'] = orig_num_leaves + num_leaves\n",
    "    \n",
    "    # go up the hypernym chain and update the leaves\n",
    "    h = abstraction_tree.loc[synset, 'HYPERNYM']\n",
    "    if len(h) != 0:\n",
    "        update_num_leaves(h[0], num_leaves)\n",
    "\n",
    "def grow_abstraction_tree(abstraction_tree):\n",
    "    \"\"\"Takes an initial abstraction tree (containing only leaves) and grows\n",
    "    the rest of the tree.\"\"\"\n",
    "    \n",
    "    synset_list = list(abstraction_tree['SYNSET'])\n",
    "\n",
    "    for s in tqdm(synset_list):\n",
    "        h = s.hypernyms()\n",
    "\n",
    "        if len(h) == 0:\n",
    "            continue\n",
    "\n",
    "        h = h[0]\n",
    "\n",
    "        if h not in abstraction_tree.SYNSET:\n",
    "            synset_list.append(h)\n",
    "            abstraction_tree.loc[h] = [\n",
    "                h,    # SYNSET\n",
    "                None, # WORD\n",
    "                0,    # DIST2LEAF\n",
    "                0,    # NUM_LEAVES\n",
    "                [],   # HYPERNYM\n",
    "                [],   # HYPONYMS\n",
    "                None  # EMBEDDING\n",
    "            ]\n",
    "\n",
    "        # Set DIST2LEAF\n",
    "        s_dist = abstraction_tree.loc[s, 'DIST2LEAF']\n",
    "        update_dist2leaf(h, s_dist+1)\n",
    "        #h_dist = abstraction_tree.loc[h, 'DIST2LEAF']\n",
    "        #print(s)\n",
    "        #if s_dist >= h_dist:\n",
    "            #while abstraction_tree.loc[h, 'DIST2LEAF']\n",
    "            #abstraction_tree.loc[h, 'DIST2LEAF'] = s_dist + 1\n",
    "\n",
    "        # Set NUM_LEAVES\n",
    "        s_num_leaves = abstraction_tree.loc[s, 'NUM_LEAVES']\n",
    "        update_num_leaves(h, s_num_leaves)\n",
    "        #h_num_leaves = abstraction_tree.loc[h, 'NUM_LEAVES']\n",
    "        #abstraction_tree.loc[h, 'NUM_LEAVES'] = h_num_leaves + s_num_leaves\n",
    "\n",
    "        # Add hypernym to synset\n",
    "        abstraction_tree.loc[s, 'HYPERNYM'] = [h]\n",
    "\n",
    "        # Add synset to hypernym\n",
    "        abstraction_tree.loc[h, 'HYPONYMS'].append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2757dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display abstraction tree\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def build_display_tree(df, root_synset, char_limit=20):\n",
    "    \"\"\"Display an abstraction tree starting with the root_synset.\n",
    "    Returns an nltk Tree structure.\n",
    "    Do not use on big trees!\"\"\"\n",
    "    row = df.loc[root_synset]\n",
    "    root_name = row['SYNSET'].lemmas()[0].name()[:char_limit]\n",
    "    if len(row['HYPONYMS']) == 0:\n",
    "        return root_name\n",
    "    \n",
    "    children = [build_display_tree(df, h, char_limit) for h in row['HYPONYMS']]\n",
    "    \n",
    "    return Tree(root_name, children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37447ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced26728970944c2bfeeffdec3aaeac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#abstraction_tree = init_abstraction_tree(9)\n",
    "abstraction_tree = init_abstraction_tree(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d643b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#abstraction_tree.loc[wn.synset('chordate.n.01'), 'DIST2LEAF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46691939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cab38d422a4405eb3514d072465d763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grow_abstraction_tree(abstraction_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5e2b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_display_tree(abstraction_tree, wn.synset('entity.n.01'), char_limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe51cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f12043f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Positive Synsets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32f959d5",
   "metadata": {},
   "source": [
    "Concrete ideas (synsets) already have embeddings.  We want to get embeddings for more abstract ideas.\n",
    "\n",
    "We will try to add a clasifier to each abstract idea (synset).\n",
    "\n",
    "Every classifier will need a set of positive embeddings to train on.\n",
    "\n",
    "These embeddings will come from the hyponym synsets.\n",
    "\n",
    "If there are not enough synsets under a hypernym, then it will not get a classifier.\n",
    "\n",
    "\n",
    "We'll want to do a breadth first search...\n",
    "We can use NUM_LEAVES to tell us if a particular synset will have a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc47365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of positive examples we want for each classifier\n",
    "#pos_count = 3\n",
    "#neg_count = 9\n",
    "pos_count = 10\n",
    "neg_count = 20\n",
    "\n",
    "\n",
    "def is_leaf(synset):\n",
    "    if synset not in abstraction_tree.index:\n",
    "        return False\n",
    "    return abstraction_tree.loc[synset, 'DIST2LEAF'] == 0\n",
    "\n",
    "def classifier_capable(synset):\n",
    "    return abstraction_tree.loc[synset, 'NUM_LEAVES'] >= pos_count\n",
    "\n",
    "def is_embedding_capable(synset):\n",
    "    \"\"\"Return true if the synset is capable of having an embedding.\"\"\"\n",
    "    if synset not in abstraction_tree.index:\n",
    "        return False\n",
    "    return is_leaf(synset) or classifier_capable(synset)\n",
    "\n",
    "# dist2leaf gives us the furthest leaf.\n",
    "# This can be used as a \"sort\" of way to determine abstraction level\n",
    "def dist2leaf(synset):\n",
    "    return abstraction_tree.loc[synset, 'DIST2LEAF']\n",
    "\n",
    "def is_closer_to_leaf(synset, dist):\n",
    "    \"\"\"Return true if the synset is closer to a leaf than dist.\"\"\"\n",
    "    return dist2leaf(synset) < dist\n",
    "\n",
    "def get_hyponyms(synset):\n",
    "    \"\"\"Return a list of hyponyms, or itself if there are none.\"\"\"\n",
    "    if synset not in abstraction_tree.index:\n",
    "        return None\n",
    "    hypos = abstraction_tree.loc[synset, 'HYPONYMS']\n",
    "    if len(hypos) == 0:\n",
    "        return [synset]\n",
    "    else:\n",
    "        return hypos\n",
    "\n",
    "def count_embedding_capable(synset_list):\n",
    "    \"\"\"Given a list of synsets, returns a count of how many are capable of having an embedding.\"\"\"\n",
    "    return sum((is_embedding_capable(s) == True)*1 for s in synset_list)\n",
    "\n",
    "def expand_hyponym_list(synset_list):\n",
    "    hypos = []\n",
    "    for s in synset_list:\n",
    "        hypos += get_hyponyms(s)\n",
    "    return hypos\n",
    "\n",
    "def remove_embedding_incapable(synset_list):\n",
    "    synset_list = np.array(synset_list)\n",
    "    return list(synset_list[list(map(is_embedding_capable, synset_list))])\n",
    "\n",
    "def find_positive_examples(synset, depth=100):\n",
    "    pos = get_hyponyms(synset)\n",
    "    for _ in range(depth):\n",
    "        pos = expand_hyponym_list(pos)\n",
    "        if count_embedding_capable(pos) >= pos_count:\n",
    "            return remove_embedding_incapable(pos)\n",
    "    \n",
    "    raise Exception(\"Reached depth of {} without finding enough positive example: {}\".format(depth, synset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da84b0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cone.n.01'),\n",
       " Synset('cake.n.01'),\n",
       " Synset('raft.n.01'),\n",
       " Synset('pill.n.01'),\n",
       " Synset('canopy.n.01'),\n",
       " Synset('cloak.n.01'),\n",
       " Synset('mask.n.01'),\n",
       " Synset('canvas.n.01'),\n",
       " Synset('tartan.n.01'),\n",
       " Synset('silk.n.01'),\n",
       " Synset('velvet.n.01'),\n",
       " Synset('wool.n.01'),\n",
       " Synset('paisley.n.01'),\n",
       " Synset('knit.n.01'),\n",
       " Synset('linen.n.01'),\n",
       " Synset('graffito.n.01'),\n",
       " Synset('rope.n.01'),\n",
       " Synset('teddy.n.01'),\n",
       " Synset('doll.n.01'),\n",
       " Synset('lego.n.01'),\n",
       " Synset('playhouse.n.01'),\n",
       " Synset('menagerie.n.02'),\n",
       " Synset('screen.n.01'),\n",
       " Synset('gun_muzzle.n.01'),\n",
       " Synset('brick.n.01'),\n",
       " Synset('asphalt.n.01'),\n",
       " Synset('pool.n.01'),\n",
       " Synset('fountain.n.01'),\n",
       " Synset('balcony.n.01'),\n",
       " Synset('airdock.n.01'),\n",
       " Synset('building.n.01'),\n",
       " Synset('area.n.05'),\n",
       " Synset('public_toilet.n.01'),\n",
       " Synset('tape.n.01'),\n",
       " Synset('conveyance.n.03'),\n",
       " Synset('container.n.01'),\n",
       " Synset('device.n.01'),\n",
       " Synset('equipment.n.01'),\n",
       " Synset('furnishing.n.02'),\n",
       " Synset('implement.n.01'),\n",
       " Synset('consumer_goods.n.01')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_positive_examples(wn.synset('artifact.n.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698faad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83351713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find negative examples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5808468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_negative_examples(synset, pos_examples):\n",
    "    # All synsets\n",
    "    neg = np.array(abstraction_tree['SYNSET'])\n",
    "    # Embedding capable synsets\n",
    "    neg = neg[list(map(is_embedding_capable, neg))]\n",
    "    # Use only more concrete words (words that are closer to a leaf)\n",
    "    dist2leaf = abstraction_tree.loc[synset, 'DIST2LEAF']\n",
    "    neg = neg[list(map(lambda x: is_closer_to_leaf(x, dist2leaf), neg))]\n",
    "    # neg examples not in positive examples\n",
    "    neg = set(neg) - set(pos_examples)\n",
    "    # Don't include yourself\n",
    "    #neg.remove(synset) # removed by the closer check\n",
    "    neg_examples = random.sample(list(neg), k=min(neg_count, len(neg)))\n",
    "    return neg_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "142dcbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_examples = find_positive_examples(wn.synset('entity.n.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d1024d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_examples = find_negative_examples(wn.synset('entity.n.01'), pos_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9664c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('grillroom.n.01'),\n",
       " Synset('keyboard.n.01'),\n",
       " Synset('cloak.n.01'),\n",
       " Synset('leash.n.01'),\n",
       " Synset('hero.n.04'),\n",
       " Synset('asphalt.n.01'),\n",
       " Synset('scalp.n.01'),\n",
       " Synset('whorehouse.n.01'),\n",
       " Synset('cow.n.01'),\n",
       " Synset('cemetery.n.01'),\n",
       " Synset('banjo.n.01'),\n",
       " Synset('wasp.n.01'),\n",
       " Synset('racetrack.n.01'),\n",
       " Synset('shovel.n.01'),\n",
       " Synset('limestone.n.01'),\n",
       " Synset('pen.n.01'),\n",
       " Synset('foundry.n.01'),\n",
       " Synset('table.n.01'),\n",
       " Synset('terminal.n.01'),\n",
       " Synset('bow.n.01')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a488271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_positive_negative_examples(synset):\n",
    "    pos = find_positive_examples(synset)\n",
    "    abstraction_tree.at[synset, 'POSITIVE'] = pos\n",
    "    neg = find_negative_examples(synset, pos)\n",
    "    abstraction_tree.at[synset, 'NEGATIVE'] = neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34075a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_capable():\n",
    "    \"\"\"Get a list of synsets capable of having a classifier.\"\"\"\n",
    "    return [s for s in abstraction_tree['SYNSET'] if classifier_capable(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c3df415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pos_neg_all():\n",
    "    \"\"\"Add positive and negative examples for each calssifier capable synset.\"\"\"\n",
    "    abstraction_tree['POSITIVE'] = [[]]*len(abstraction_tree)\n",
    "    abstraction_tree['NEGATIVE'] = [[]]*len(abstraction_tree)\n",
    "    for s in get_classifier_capable():\n",
    "        add_positive_negative_examples(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ffbc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pos_neg_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b23aecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Train/Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa95f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test(synset):\n",
    "    pos_examples = find_positive_examples(synset)\n",
    "    neg_examples = find_negative_examples(synset, pos_examples)\n",
    "    X = pos_examples + neg_examples\n",
    "    y = list(np.ones(len(pos_examples))) + list(np.zeros(len(neg_examples)))\n",
    "    return train_test_split(X, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ed80df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_out_train_test():\n",
    "    abstraction_tree['X_TRAIN'] = [[]]*len(abstraction_tree)\n",
    "    abstraction_tree['X_TEST']  = [[]]*len(abstraction_tree)\n",
    "    abstraction_tree['Y_TRAIN'] = [[]]*len(abstraction_tree)\n",
    "    abstraction_tree['Y_TEST']  = [[]]*len(abstraction_tree)\n",
    "    \n",
    "    synsets = get_classifier_capable()\n",
    "    for s in synsets:\n",
    "        X_train, X_test, y_train, y_test  = build_train_test(s)\n",
    "        abstraction_tree.at[s, 'X_TRAIN'] = X_train\n",
    "        abstraction_tree.at[s, 'X_TEST']  = X_test\n",
    "        abstraction_tree.at[s, 'Y_TRAIN'] = y_train\n",
    "        abstraction_tree.at[s, 'Y_TEST']  = y_test        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c10377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_out_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ec987a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "928332ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b3cfd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbdaadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefs(classifier):\n",
    "    return classifier.coef_[0]\n",
    "\n",
    "def build_classifiers():\n",
    "    abstraction_tree['CLASSIFIER']  = [None]*len(abstraction_tree)\n",
    "    cc = get_classifier_capable()\n",
    "    # Start with synsets close to leaves and work our way up to more abstract hypernyms\n",
    "    cc.sort(key=dist2leaf)\n",
    "    for ss in cc:\n",
    "        #print(ss)\n",
    "        X_train = abstraction_tree.loc[ss, 'X_TRAIN']\n",
    "        y_train = abstraction_tree.loc[ss, 'Y_TRAIN']\n",
    "        X_train = list(abstraction_tree.loc[X_train, 'EMBEDDING'])\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        abstraction_tree.at[ss, 'CLASSIFIER'] = lr\n",
    "        abstraction_tree.at[ss, 'EMBEDDING'] = coefs(lr)\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8114aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8055221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#abstraction_tree.loc[get_classifier_capable(), 'EMBEDDING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58591b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dba63aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Baseline (For a single classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53d64e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_random_baseline():\n",
    "    pos, tot = 0, 0\n",
    "    for ss in get_classifier_capable():\n",
    "        y = abstraction_tree.loc[ss, 'Y_TRAIN']\n",
    "        pos += sum(y)\n",
    "        tot += len(y)\n",
    "        y = abstraction_tree.loc[ss, 'Y_TEST']\n",
    "        pos += sum(y)\n",
    "        tot += len(y)\n",
    "    return pos/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "172161be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4146341463414634"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_random_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a6c9550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Common Baseline (For a single classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc95cf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5853658536585367"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-calc_random_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39480503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7f51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1a3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbddfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32626281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate (vs negative examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11ace8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifiers():\n",
    "    golds = []\n",
    "    preds = []\n",
    "    cc = get_classifier_capable()\n",
    "    # Evaluate in order (Not stricly needed, but helpful)\n",
    "    cc.sort(key=dist2leaf)\n",
    "    for ss in cc:\n",
    "        X_test = abstraction_tree.loc[ss, 'X_TEST']\n",
    "        y_test = abstraction_tree.loc[ss, 'Y_TEST']\n",
    "        X_test = list(abstraction_tree.loc[X_test, 'EMBEDDING'])\n",
    "        \n",
    "        c = abstraction_tree.loc[ss, 'CLASSIFIER']\n",
    "        pred = c.predict_proba(X_test)\n",
    "        #pred = lr.predict_proba(X_test)\n",
    "        pred = list(np.argmax(pred, axis=1))\n",
    "        print(ss)\n",
    "        print(list(map(int, y_test)))\n",
    "        print(pred)\n",
    "        print(metrics.accuracy_score(y_test, pred))\n",
    "        print()\n",
    "        preds = preds + pred\n",
    "        golds = golds + y_test\n",
    "    return metrics.accuracy_score(golds, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87bc79dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('wood.n.01')\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "0.8181818181818182\n",
      "\n",
      "Synset('fabric.n.01')\n",
      "[0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
      "0.9090909090909091\n",
      "\n",
      "Synset('body_of_water.n.01')\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('plant_material.n.01')\n",
      "[0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "0.7272727272727273\n",
      "\n",
      "Synset('self-propelled_vehicle.n.01')\n",
      "[1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "1.0\n",
      "\n",
      "Synset('dish.n.02')\n",
      "[0, 0, 0, 1, 1, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "0.9\n",
      "\n",
      "Synset('furniture.n.01')\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('garment.n.01')\n",
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "0.7272727272727273\n",
      "\n",
      "Synset('room.n.01')\n",
      "[1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "0.9166666666666666\n",
      "\n",
      "Synset('vessel.n.03')\n",
      "[0, 1, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "0.8\n",
      "\n",
      "Synset('collection.n.01')\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('vessel.n.02')\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "0.9090909090909091\n",
      "\n",
      "Synset('alcohol.n.01')\n",
      "[0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
      "[0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1]\n",
      "0.7272727272727273\n",
      "\n",
      "Synset('building.n.01')\n",
      "[0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1]\n",
      "[0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
      "0.8571428571428571\n",
      "\n",
      "Synset('clothing.n.01')\n",
      "[0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('beverage.n.01')\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]\n",
      "[1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1]\n",
      "0.9090909090909091\n",
      "\n",
      "Synset('area.n.05')\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "0.8333333333333334\n",
      "\n",
      "Synset('geological_formation.n.01')\n",
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "[0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "0.6666666666666666\n",
      "\n",
      "Synset('tree.n.01')\n",
      "[0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "0.8\n",
      "\n",
      "Synset('external_body_part.n.01')\n",
      "[0, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "0.8\n",
      "\n",
      "Synset('decoration.n.01')\n",
      "[1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "0.8\n",
      "\n",
      "Synset('fruit.n.01')\n",
      "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "1.0\n",
      "\n",
      "Synset('wheeled_vehicle.n.01')\n",
      "[1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "[1, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "0.9\n",
      "\n",
      "Synset('bird.n.01')\n",
      "[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1]\n",
      "[0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "0.9230769230769231\n",
      "\n",
      "Synset('organ.n.01')\n",
      "[0, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "0.9\n",
      "\n",
      "Synset('nutriment.n.01')\n",
      "[1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "[1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "1.0\n",
      "\n",
      "Synset('chemical.n.01')\n",
      "[0, 1, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('furnishing.n.02')\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.8\n",
      "\n",
      "Synset('covering.n.01')\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "0.6666666666666666\n",
      "\n",
      "Synset('structure.n.04')\n",
      "[0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "0.6363636363636364\n",
      "\n",
      "Synset('geographical_area.n.01')\n",
      "[0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('herb.n.01')\n",
      "[0, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
      "0.9\n",
      "\n",
      "Synset('container.n.01')\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "0.6875\n",
      "\n",
      "Synset('body_part.n.01')\n",
      "[0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1]\n",
      "[0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
      "0.8461538461538461\n",
      "\n",
      "Synset('covering.n.02')\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.6363636363636364\n",
      "\n",
      "Synset('weapon.n.01')\n",
      "[0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('food.n.02')\n",
      "[1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "0.8461538461538461\n",
      "\n",
      "Synset('equipment.n.01')\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "0.6\n",
      "\n",
      "Synset('material.n.01')\n",
      "[1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "0.6923076923076923\n",
      "\n",
      "Synset('musical_instrument.n.01')\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "0.9166666666666666\n",
      "\n",
      "Synset('woody_plant.n.01')\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
      "[0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "0.5\n",
      "\n",
      "Synset('implement.n.01')\n",
      "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "0.5833333333333334\n",
      "\n",
      "Synset('way.n.06')\n",
      "[0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
      "[0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "0.8461538461538461\n",
      "\n",
      "Synset('arthropod.n.01')\n",
      "[0, 0, 1, 0, 1, 0, 0, 1, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "0.9\n",
      "\n",
      "Synset('reproductive_structure.n.01')\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "0.9090909090909091\n",
      "\n",
      "Synset('craft.n.02')\n",
      "[1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.8181818181818182\n",
      "\n",
      "Synset('region.n.03')\n",
      "[0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0]\n",
      "[0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0]\n",
      "1.0\n",
      "\n",
      "Synset('part.n.03')\n",
      "[0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.5\n",
      "\n",
      "Synset('foodstuff.n.02')\n",
      "[0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "0.8181818181818182\n",
      "\n",
      "Synset('solid.n.01')\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
      "0.9090909090909091\n",
      "\n",
      "Synset('structure.n.01')\n",
      "[1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "[1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1]\n",
      "0.6470588235294118\n",
      "\n",
      "Synset('even-toed_ungulate.n.01')\n",
      "[0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "[0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "0.9090909090909091\n",
      "\n",
      "Synset('vascular_plant.n.01')\n",
      "[1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0]\n",
      "[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "0.7142857142857143\n",
      "\n",
      "Synset('consumer_goods.n.01')\n",
      "[0, 0, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "0.8\n",
      "\n",
      "Synset('plant_organ.n.01')\n",
      "[0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.6363636363636364\n",
      "\n",
      "Synset('worker.n.01')\n",
      "[0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "0.8181818181818182\n",
      "\n",
      "Synset('vehicle.n.01')\n",
      "[0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0]\n",
      "[1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "0.8461538461538461\n",
      "\n",
      "Synset('instrument.n.01')\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "0.8\n",
      "\n",
      "Synset('activity.n.01')\n",
      "[1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "0.6\n",
      "\n",
      "Synset('substance.n.01')\n",
      "[0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "0.6875\n",
      "\n",
      "Synset('invertebrate.n.01')\n",
      "[1, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "0.9\n",
      "\n",
      "Synset('conveyance.n.03')\n",
      "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "0.7272727272727273\n",
      "\n",
      "Synset('plant_part.n.01')\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1]\n",
      "0.7272727272727273\n",
      "\n",
      "Synset('person.n.01')\n",
      "[0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n",
      "0.6153846153846154\n",
      "\n",
      "Synset('device.n.01')\n",
      "[0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1]\n",
      "[0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
      "0.7142857142857143\n",
      "\n",
      "Synset('thing.n.12')\n",
      "[1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0]\n",
      "[1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0]\n",
      "0.6666666666666666\n",
      "\n",
      "Synset('ungulate.n.01')\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "[0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "0.9090909090909091\n",
      "\n",
      "Synset('creation.n.02')\n",
      "[0, 1, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('food.n.01')\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0]\n",
      "0.9333333333333333\n",
      "\n",
      "Synset('location.n.01')\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "0.6363636363636364\n",
      "\n",
      "Synset('natural_phenomenon.n.01')\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('plant.n.02')\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0]\n",
      "[1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "0.7142857142857143\n",
      "\n",
      "Synset('commodity.n.01')\n",
      "[0, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('placental.n.01')\n",
      "[0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0]\n",
      "0.8181818181818182\n",
      "\n",
      "Synset('natural_object.n.01')\n",
      "[0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "0.6363636363636364\n",
      "\n",
      "Synset('instrumentality.n.03')\n",
      "[0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
      "[1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "0.7857142857142857\n",
      "\n",
      "Synset('substance.n.07')\n",
      "[0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "0.7272727272727273\n",
      "\n",
      "Synset('shape.n.02')\n",
      "[0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "0.6666666666666666\n",
      "\n",
      "Synset('communication.n.02')\n",
      "[0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "0.7272727272727273\n",
      "\n",
      "Synset('causal_agent.n.01')\n",
      "[0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
      "[1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]\n",
      "0.6923076923076923\n",
      "\n",
      "Synset('act.n.02')\n",
      "[0, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('phenomenon.n.01')\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "0.8\n",
      "\n",
      "Synset('artifact.n.01')\n",
      "[0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0]\n",
      "[1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "0.6666666666666666\n",
      "\n",
      "Synset('mammal.n.01')\n",
      "[1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "[1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "0.9166666666666666\n",
      "\n",
      "Synset('matter.n.03')\n",
      "[0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1]\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "0.7272727272727273\n",
      "\n",
      "Synset('social_group.n.01')\n",
      "[0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.6363636363636364\n",
      "\n",
      "Synset('cognition.n.01')\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "0.6\n",
      "\n",
      "Synset('attribute.n.02')\n",
      "[0, 1, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('event.n.01')\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7272727272727273\n",
      "\n",
      "Synset('process.n.06')\n",
      "[0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.6363636363636364\n",
      "\n",
      "Synset('vertebrate.n.01')\n",
      "[1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0]\n",
      "[0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "0.6666666666666666\n",
      "\n",
      "Synset('group.n.01')\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "0.5454545454545454\n",
      "\n",
      "Synset('psychological_feature.n.01')\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.7\n",
      "\n",
      "Synset('chordate.n.01')\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1]\n",
      "[0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1]\n",
      "0.7333333333333333\n",
      "\n",
      "Synset('abstraction.n.06')\n",
      "[0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0.6842105263157895\n",
      "\n",
      "Synset('animal.n.01')\n",
      "[0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "0.8181818181818182\n",
      "\n",
      "Synset('organism.n.01')\n",
      "[0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "0.6153846153846154\n",
      "\n",
      "Synset('living_thing.n.01')\n",
      "[0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1]\n",
      "[1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "0.5\n",
      "\n",
      "Synset('whole.n.02')\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "[1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n",
      "0.8333333333333334\n",
      "\n",
      "Synset('object.n.01')\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "[1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n",
      "0.75\n",
      "\n",
      "Synset('physical_entity.n.01')\n",
      "[0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "[0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "1.0\n",
      "\n",
      "Synset('entity.n.01')\n",
      "[0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n",
      "[0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n",
      "0.9166666666666666\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7588235294117647"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae684fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28943667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c762a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate (vs distractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a1b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d805b0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ss \u001b[38;5;241m=\u001b[39m \u001b[43mcc\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cc' is not defined"
     ]
    }
   ],
   "source": [
    "ss = cc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc18f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13326080",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstraction_tree.loc[ss, 'X_TRAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = abstraction_tree.loc[ss, 'X_TRAIN']\n",
    "y_train = abstraction_tree.loc[ss, 'Y_TRAIN']\n",
    "X_train = list(abstraction_tree.loc[X_train, 'EMBEDDING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bc72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50fd7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e5247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = abstraction_tree.loc[ss, 'X_TEST']\n",
    "y_test = abstraction_tree.loc[ss, 'Y_TEST']\n",
    "X_test = list(abstraction_tree.loc[X_test, 'EMBEDDING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41171d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[1] = [.2, .6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75714762",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff48dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55c1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4465b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faadf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c2131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstraction_tree.loc[ss, 'X_TRAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15209239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_display_tree(abstraction_tree, wn.synset('entity.n.01'), char_limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847b81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d8060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0486906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstraction_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f259fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
